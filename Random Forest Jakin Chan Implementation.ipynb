{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45bc0bc-123f-4d02-8fb6-aea274a76df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees: 1\n",
      "maxDepth: 2\n",
      "k_folds: 2\n",
      "sample_size: 0.100000\n",
      "Mean Accuracy: 57.752%\n",
      "Mean Recall: 76.055%\n",
      "Mean Precision: 28.688%\n",
      "6.904479503631592\n",
      "seconds\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# from IPython.display import display\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy import stats\n",
    "\n",
    "from random import seed\n",
    "from random import randrange\n",
    "import time\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "from math import inf\n",
    "\n",
    "# Load CSV File\n",
    "def load_csv(filename, features):\n",
    " dataset = list()\n",
    " rowNum = 1\n",
    " with open(filename, 'r') as file:\n",
    "    csv_reader = reader(file)\n",
    "    for row in csv_reader:\n",
    "        if not row:\n",
    "            continue\n",
    "        if rowNum == 1:\n",
    "            rowNum = 2\n",
    "            features.append(row)\n",
    "        else:\n",
    "            dataset.append(row)\n",
    " return dataset\n",
    "            \n",
    "# Table to Float\n",
    "def table_to_float(dataset):\n",
    "\tfor i in range(0, len(dataset[0])):\n",
    "\t\tfor row in dataset: \n",
    "\t\t\tif row[i] == 'True':\n",
    "\t\t\t\trow[i] = 1.0\n",
    "\t\t\tif row[i] == 'False':\n",
    "\t\t\t\trow[i] = 0.0\n",
    "\t\t\tif isinstance(row[i], str):\n",
    "\t\t\t\trow[i] = float(row[i])\n",
    "\n",
    "def cross_validation_split(dataset, k_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / k_folds)\n",
    "\tfor i in range(k_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(0, len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "def calcGini(groups, classes):\n",
    "\ttotal = 0.0\n",
    "\tfor grouping in groups:\n",
    "\t\ttotal += float(len(grouping))\n",
    "\tgini = 0.0\n",
    "\tfor grouping in groups:\n",
    "\t\tif float(len(grouping)) == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tscore = 0.0\n",
    "\t\tfor class_val in classes:\n",
    "\t\t\tp = [row[-1] for row in grouping].count(class_val) / float(len(grouping))\n",
    "\t\t\tscore += p * p\n",
    "\t\tgini += (1.0 - score) * (float(len(grouping)) / total)\n",
    "\treturn gini\n",
    "\n",
    "def splitDataset(index, value, dataset):\n",
    "\tright, left = list(), list()\n",
    "\tfor row in dataset:\n",
    "\t\tif row[index] >= value:\n",
    "\t\t\tright.append(row)\n",
    "\t\telse:\n",
    "\t\t\tleft.append(row)\n",
    "\treturn left, right\n",
    "\n",
    "def get_split(dataset, n_features):\n",
    "\tclass_values = list(set(row[-1] for row in dataset))\n",
    "\tb_index, b_value, b_score, b_groups = float(inf), float(inf), float(inf), None\n",
    "\tfeatures = list()\n",
    "\tfor x in range(n_features):\n",
    "\t\tindex = randrange(0, len(dataset[0])-1)\n",
    "\t\tif index not in features:\n",
    "\t\t\tfeatures.append(index)\n",
    "\tfor index in features:\n",
    "\t\tfor row in dataset:\n",
    "\t\t\tgroups = splitDataset(index, row[index], dataset)\n",
    "\t\t\tgini = calcGini(groups, class_values)\n",
    "\t\t\tif gini < b_score:\n",
    "\t\t\t\tb_index, b_groups, b_value, b_score, = index, groups, row[index], gini\n",
    "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "def leaf(group):\n",
    "\toutcomes = list()\n",
    "\tfor row in group:\n",
    "\t\toutcomes.append(row[-1])\n",
    "\treturn max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "# Create child splits for a node or make terminal\n",
    "def splitNode(node, maxDepth,  min_sample_split, numFeatures, depth):\n",
    "\tleft, right = node['groups']\n",
    "\tdel(node['groups'])\n",
    "\tif not right or not left:\n",
    "\t\tnode['left'] = node['right'] = leaf(right + left)\n",
    "\t\treturn\n",
    "\tif depth >= maxDepth:\n",
    "\t\tnode['left'], node['right'] = leaf(left), leaf(right)\n",
    "\t\treturn\n",
    "\tif len(right) > min_sample_split:\n",
    "\t\tnode['right'] = get_split(right, numFeatures)\n",
    "\t\tsplitNode(node['right'], maxDepth,  min_sample_split, numFeatures, depth+1)\n",
    "\telse:\n",
    "\t\tnode['right'] = leaf(right)\n",
    "\tif len(left) >  min_sample_split:\n",
    "\t\tnode['left'] = get_split(left, numFeatures)\n",
    "\t\tsplitNode(node['left'], maxDepth,  min_sample_split, numFeatures, depth+1)\t\t\n",
    "\telse:\n",
    "  \t\tnode['left'] = leaf(left)\n",
    "\n",
    "def predict(node, row):\n",
    "\tif row[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']\n",
    "\n",
    "def subsample(dataset, ratio):\n",
    "\tsample = list()\n",
    "\tnumSample = round(len(dataset) * ratio)\n",
    "\tfor x in range(numSample):\n",
    "\t\tindex = randrange(0, len(dataset))\n",
    "\t\tsample.append(dataset[index])\n",
    "\treturn sample\n",
    "\n",
    "def bagging_predict(trees, row):\n",
    "\tpredictions = [predict(tree, row) for tree in trees]\n",
    "\treturn max(set(predictions), key=predictions.count)\n",
    "\n",
    "def fit(train, test, maxDepth, min_sample_split, sample_size, numTrees, numfeatures):\n",
    "\ttrees = list()\n",
    "\tfor i in range(numTrees):\n",
    "\t\ttrees.append(decisionTree(subsample(train, sample_size), maxDepth, min_sample_split, numfeatures))\n",
    "\tpredictions = [bagging_predict(trees, row) for row in test]\n",
    "\treturn(predictions)\n",
    "\n",
    "def decisionTree(train, maxDepth,  min_sample_split, numFeatures):\n",
    "\troot = get_split(train, numFeatures)\n",
    "\tsplitNode(root, maxDepth,  min_sample_split, numFeatures, 1)\n",
    "\treturn root\n",
    "\n",
    "def evaluate_algorithm(dataset, k_folds, maxDepth,  min_sample_split, sample_size, n_trees, n_features):\n",
    "\tfolds = cross_validation_split(dataset, k_folds)\n",
    "\tacc, rec, pre = list(), list(), list()\n",
    "\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\n",
    "\t\ty_pred = fit(train_set, test_set, maxDepth,  min_sample_split, sample_size, n_trees, n_features)\n",
    "\t\ty_test = [row[-1] for row in fold]\n",
    "\t\tacc.append(accuracy_score(y_test, y_pred)* 100.00)\n",
    "\t\tpre.append(precision_score(y_test, y_pred)* 100.0)\n",
    "\t\trec.append(recall_score(y_test, y_pred)* 100.0)\n",
    "\treturn acc, rec, pre\n",
    "\n",
    "filename = 'downsampled.csv'\n",
    "features = list()\n",
    "dataset = load_csv(filename, features)\n",
    "\n",
    "# Convert everything to floats\n",
    "table_to_float(dataset)\n",
    "\n",
    "seed(2)\n",
    "k_folds = 2\n",
    "maxDepth = 2\n",
    "min_sample_split = 5\n",
    "sample_size = 0.1\n",
    "numFeatures = int(sqrt(len(dataset[0])-1))\n",
    "numTrees = 1\n",
    "\n",
    "start = time.time()\n",
    "acc, pre, rec = evaluate_algorithm(dataset, k_folds, maxDepth, min_sample_split, sample_size, numTrees, numFeatures)\n",
    "print('Trees: %d' % numTrees)\n",
    "print('maxDepth: %d' % maxDepth)\n",
    "print('k_folds: %d' % k_folds)\n",
    "print('sample_size: %f' % sample_size)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(acc)/float(len(acc))))\n",
    "print('Mean Recall: %.3f%%' % (sum(rec)/float(len(rec))))\n",
    "print('Mean Precision: %.3f%%' % (sum(pre)/float(len(pre))))\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(\"seconds\")\n",
    "\n",
    "print(\"hi\")\n",
    "#random state, n estimators default criterion, max depth, min size, n features, n estimators\n",
    "\n",
    "# Sources:\n",
    "# https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd\n",
    "# https://www.datacamp.com/tutorial/k-nearest-neighbor-classification-scikit-learn\n",
    "# https://www.ritchieng.com/machinelearning-one-hot-encoding/\n",
    "\n",
    "# https://www.datacamp.com/tutorial/random-forests-classifier-python\n",
    "# https://thecleverprogrammer.com/2020/12/17/why-random_state42-in-machine-learning/\n",
    "# https://www.w3schools.com/python/ref_func_open.asp\n",
    "# https://wellsr.com/python/upsampling-and-downsampling-imbalanced-data-in-python/\n",
    "# https://www.geeksforgeeks.org/how-to-remove-an-item-from-the-list-in-python/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08862f42-10b2-40ad-aaf6-1f9d2244d2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f46175c-1fc9-426f-b8e3-b273791c0f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
